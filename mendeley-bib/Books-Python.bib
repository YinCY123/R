Automatically generated by Mendeley Desktop 1.19.4
Any changes to this file will be lost if it is regenerated by Mendeley.

BibTeX export options can be customized via Options -> BibTeX in Mendeley Desktop

@book{Matthes2016a,
abstract = {2nd edition. Includes index. This is the second edition of the best selling Python book in the world. Python Crash Course, 2nd Edition is a straightforward introduction to the core of Python programming. Author Eric Matthes dispenses with the sort of tedious, unnecessary information that can get in the way of learning how to program, choosing instead to provide a foundation in general programming concepts, Python fundamentals, and problem solving. Three real world projects in the second part of the book allow readers to apply their knowledge in useful ways. Readers will learn how to create a simple video game, use data visualization techniques to make graphs and charts, and build and deploy an interactive web application. Python Crash Course, 2nd Edition teaches beginners the essentials of Python quickly so that they can build practical programs and develop powerful programming techniques. - Amazon.com. Basics. Getting started ; Variables and simple data types ; Introducing lists ; Working with lists ; If statements ; Dictionaries ; User input and while loops ; Functions ; Classes ; Files and exceptions ; Testing your code -- Projects. Project 1, Alien invasion. A ship that fires bullets ; Aliens! ; Scoring -- Project 2, Data visualization. Generating data ; Downloading data ; Working with APIs -- Project 3, Web applications. Getting started with Django ; User accounts ; Styling and deploying an app -- Afterword. A. Installation and troubleshooting -- B. Text editors and IDEs -- C. Getting help -- D. Using Git for version control.},
author = {Matthes, Eric},
file = {:C$\backslash$:/Users/YinCY/Documents/Mendeley Desktop/Matthes/Unknown/Matthes - 2016 - Python Cash Course.pdf:pdf},
isbn = {9781593276034},
pages = {562},
title = {{Python Cash Course}},
year = {2016}
}
@book{Hagan2017a,
author = {Hagan, Kate},
file = {:C$\backslash$:/Users/YinCY/Documents/Mendeley Desktop/Hagan/Unknown/Hagan - 2017 - Core python applications programming.pdf:pdf},
isbn = {9780132678209},
title = {{Core python applications programming}},
year = {2017}
}
@book{Guttag2016a,
abstract = {Second edition. Includes index. This book introduces students with little or no prior programming experience to the art of computational problem solving using Python and various Python libraries, including PyLab. It provides students with skills that will enable them to make productive use of computational techniques, including some of the tools and techniques of data science for using computation to model and interpret data. The book is based on an MIT course (which became the most popular course offered through MIT's OpenCourseWare) and was developed for use not only in a conventional classroom but in a massive open online course (MOOC). This new edition has been updated for Python 3, reorganized to make it easier to use for courses that cover only a subset of the material, and offers additional material including five new chapters. Students are introduced to Python and the basics of programming in the context of such computational concepts and techniques as exhaustive enumeration, bisection search, and efficient approximation algorithms. Although it covers such traditional topics as computational complexity and simple algorithms, the book focuses on a wide range of topics not found in most introductory texts, including information visualization, simulations to model randomness, computational techniques to understand data, and statistical techniques that inform (and misinform) as well as two related but relatively advanced topics: optimization problems and dynamic programming. This edition offers expanded material on statistics and machine learning and new chapters on Frequentist and Bayesian statistics.-- Preface -- 1. Introduction -- 2. Introduction to Python. The basic elements of Python ; Objects, expressions, and numerical types ; Variables and assignment ; Python IDE's ; Branching programs ; Strings and input ; Input ; A digression about character encoding ; Iteration -- 3. Some simple numerical programs. Exhaustive enumeration ; For loops ; Approximate solutions and bisection search ; Few words about using floats ; Newton-Raphson -- 4. Functions, scoping, and abstraction. Functions and scoping ; Function definitions ; Keyword arguments and default values ; Scoping ; Specifications ; Recursion ; Fibonacci numbers ; Palindromes ; Global variables ; Modules ; Files -- 5. Structured types, mutability, and higher-order functions. Tuples ; Sequences and multiple assignment ; Ranges ; Lists and mutability ; Cloning ; List comprehension ; Functions as objects ; Strings, tuples, ranges, and lists ; Dictionaries -- 6. Testing and debugging. Testing ; Black-box testing ; Glass-box testing ; Conducting tests ; Debugging ; Learning to debug ; Designing the experiment ; When the going gets tough ; When you have found "the" bug -- 7. Exceptions and assertions. Handling exceptions ; Exceptions as a control flow mechanism ; Assertions -- 8. Classes and object-oriented programming. Abstract data types and classes ; Designing programs using abstract data types ; Using classes to keep track of students and faculty ; Inheritance ; Multiple levels of inheritance ; Substitution principle ; Encapsulation and information hiding ; Generators ; Mortgages, an extended example -- 9. A simplistic introduction to algorithmic complexity. Thinking about computational complexity ; Asymptotic notation ; Some important complexity classes ; Constant complexity ; Logarithmic complexity ; Linear complexity ; Log-linear complexity ; Polynomial complexity ; Exponential complexity ; Comparisons of complexity classes -- 10. Some simple algorithms and data structures. Search algorithms ; Linear search and using indirection to access elements ; Binary search and exploiting assumptions ; Sorting algorithms ; Merge sort ; Exploiting functions as parameters ; Sorting in Python ; Hash tables -- 11. Plotting and more about classes. Plotting using PyLab ; Plotting mortgages, an extended example -- 12. Knapsack and graph optimization problems. Knapsack problems ; Greedy algorithms ; Optimal solution to the 0/1 Knapsack problem ; Graph optimization problems ; Some classic graph-theoretic problems ; Shortest path : depth-first search and breadth-first search -- 13. Dynamic programming. Fibonacci sequences, revisited ; Dynamic programming and the 0/1 Knapsack problem ; Dynamic programming and divide-and-conquer -- 14. Random walks and more about data visualization. Random walks ; The drunkard's walk ; Biased random walks ; Treacherous fields -- 15. Stochastic programs, probability, and distributions. Stochastic programs ; Calculating simple probabilities ; Inferential statistics ; Distributions ; Probability distributions ; Normal distributions ; Continuous and discrete uniform distributions ; Binomial and multinomial distributions ; Exponential and geometric distributions ; Benford's distribution ; Hashing and collisions ; How often does the better team win? -- 16. Monte Carlo stimulation. Pascal's problem ; Pass or don't pass? ; Using table lookup to improve performance ; Finding pi ; Some closing remarks about simulation models -- 17. Sampling and confidence intervals. Sampling the Boston Marathon ; Central limit theorem ; Standard error of the mean -- 18. Understanding experimental data. The behavior of springs ; Using linear regression to find a fit ; The behavior of projectiles ; Coefficient of determination ; Using a computational model ; Fitting exponentially distributed data ; When theory is missing -- 19. Randomized trials and hypothesis checking. Checking significance ; Beware of P-values ; One-tail and one-sample tests ; Significant or not? ; Which N? ; Multiple hypotheses -- 20. Conditional probability and Bayesian statistics. Conditional probabilities ; Bayes' theorem ; Bayesian updating -- 21. Lies, damned lies, and statistics. Garbage in garbage out (GIGO) ; Tests are imperfect ; Pictures can be deceiving ; Cum hoc ergo propter hoc ; Statistical measures don't tell the whole story ; Sampling bias ; Context matters ; Beware of extrapolation ; Texas sharpshooter fallacy ; Percentages can confuse ; Statistically significant differences can be insignificant ; Regressive fallacy ; Just beware -- 22. A quick look at machine learning. Feature vectors ; Distance metrics -- 23. Clustering. Class cluster ; K-means clustering ; A contrived example ; A less contrived example -- 24. Classification methods. Evaluating classifiers ; Predicting the gender of runners ; K-nearest neighbors ; Regression-based classifiers ; Surviving the Titanic ; Wrapping up -- Python 3.5 quick reference.},
author = {Guttag, John V.},
file = {:C$\backslash$:/Users/YinCY/Documents/Mendeley Desktop/Guttag/Unknown/Guttag - 2016 - Introduction to computation and programming using Python with application to understanding data.pdf:pdf},
isbn = {9780262529624},
keywords = {Computer programming,Textbook,coding,introduction,python},
pages = {447},
title = {{Introduction to computation and programming using Python: with application to understanding data}},
url = {https://books.google.com/books?id=KabKDAAAQBAJ{\&}dq=introduction+to+computation+and+programming+using+Python+with+...+arxiv+id{\&}source=gbs{\_}navlinks{\_}s},
year = {2016}
}
@book{Intelligent2017a,
archivePrefix = {arXiv},
arxivId = {1412.3919},
author = {Intelligent, Build and Aur, Systems},
doi = {10.3389/fninf.2014.00014},
eprint = {1412.3919},
file = {:C$\backslash$:/Users/YinCY/Documents/Mendeley Desktop/Intelligent, Aur/Unknown/Intelligent, Aur - 2017 - Hands-On Machine Learning with Scikit-Learn {\&} TensorFlow.pdf:pdf},
isbn = {9781491962299},
issn = {1662-5196},
pmid = {3315986},
title = {{Hands-On Machine Learning with Scikit-Learn {\&} TensorFlow}},
year = {2017}
}
@book{McKinney1976a,
abstract = {Python for Data Analysis is concerned with the nuts and bolts of manipulating, processing, cleaning, and crunching data in Python. It is also a practical, modern introduction to scientific computing in Python, tailored for data-intensive applications. This is a book about the parts of the Python language and libraries you'll need to effectively solve a broad set of data analysis problems. This book is not an exposition on analytical methods using Python as the implementation language. Written by Wes McKinney, the main author of the pandas library, this hands-on book is packed with practical cases studies. It's ideal for analysts new to Python and for Python programmers new to scientific computing. Use the IPython interactive shell as your primary development environment Learn basic and advanced NumPy (Numerical Python) features Get started with data analysis tools in the pandas library Use high-performance tools to load, clean, transform, merge, and reshape data Create scatter plots and static or interactive visualizations with matplotlib Apply the pandas groupby facility to slice, dice, and summarize datasets Measure data by points in time, whether it's specific instances, fixed periods, or intervals Learn how to solve problems in web analytics, social sciences, finance, and economics, through detailed examples},
author = {McKinney, Wes},
booktitle = {O'Reilly Media, Inc.},
file = {:C$\backslash$:/Users/YinCY/Documents/Mendeley Desktop/McKinney/O'Reilly Media, Inc/McKinney - 1976 - Python for Data Analysis Data Wrangling with Pandas, NumPy, and IPython.pdf:pdf},
isbn = {9781491957660},
number = {5},
pages = {358--359},
title = {{Python for Data Analysis: Data Wrangling with Pandas, NumPy, and IPython}},
volume = {15},
year = {1976}
}
@book{Mitchell2018a,
abstract = {Predicting the binding mode of flexible polypeptides to proteins is an important task that falls outside the domain of applicability of most small molecule and protein−protein docking tools. Here, we test the small molecule flexible ligand docking program Glide on a set of 19 non-$\alpha$-helical peptides and systematically improve pose prediction accuracy by enhancing Glide sampling for flexible polypeptides. In addition, scoring of the poses was improved by post-processing with physics-based implicit solvent MM- GBSA calculations. Using the best RMSD among the top 10 scoring poses as a metric, the success rate (RMSD ≤ 2.0 {\AA} for the interface backbone atoms) increased from 21{\%} with default Glide SP settings to 58{\%} with the enhanced peptide sampling and scoring protocol in the case of redocking to the native protein structure. This approaches the accuracy of the recently developed Rosetta FlexPepDock method (63{\%} success for these 19 peptides) while being over 100 times faster. Cross-docking was performed for a subset of cases where an unbound receptor structure was available, and in that case, 40{\%} of peptides were docked successfully. We analyze the results and find that the optimized polypeptide protocol is most accurate for extended peptides of limited size and number of formal charges, defining a domain of applicability for this approach.},
archivePrefix = {arXiv},
arxivId = {arXiv:1011.1669v3},
author = {Mitchell, Ryan},
booktitle = {Web Scraping with Python, 2nd Edition},
doi = {10.1017/CBO9781107415324.004},
eprint = {arXiv:1011.1669v3},
file = {:C$\backslash$:/Users/YinCY/Documents/Mendeley Desktop/Mitchell/Web Scraping with Python, 2nd Edition/Mitchell - 2018 - Web Scraping with Python, 2nd Edition.pdf:pdf},
isbn = {9788578110796},
issn = {1098-6596},
keywords = {icle},
pages = {306},
pmid = {25246403},
title = {{Web Scraping with Python, 2nd Edition}},
year = {2018}
}
@book{Lutz2013a,
author = {Lutz, Mark},
file = {:C$\backslash$:/Users/YinCY/Documents/Mendeley Desktop/Lutz/Unknown/Lutz - 2013 - Learning Python, 5th Edition.pdf:pdf},
isbn = {9781449355739},
pages = {1594},
title = {{Learning Python, 5th Edition}},
year = {2013}
}
@book{Yadav2018a,
author = {Yadav, Satyajit and Subramanian, Selvakumar},
booktitle = {Manning Publications Co},
doi = {10.1109/ICCTICT.2016.7514608},
edition = {1st},
file = {:C$\backslash$:/Users/YinCY/Documents/Mendeley Desktop/Yadav, Subramanian/Manning Publications Co/Yadav, Subramanian - 2018 - Deep learning with Python.pdf:pdf},
isbn = {9781509000821},
keywords = {FRAN{\c{C}}OIS CHOLLET,tensorflow},
mendeley-tags = {tensorflow},
pages = {1--373},
publisher = {Manning Publications Co},
title = {{Deep learning with Python}},
year = {2018}
}
